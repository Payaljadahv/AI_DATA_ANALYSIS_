{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Feature Scaling\n",
    "# Task: Explain why feature scaling is essential and demonstrate the impact of unscaled features on a machine learning model.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 2: Min-Max Scaling\n",
    "# Task: Implement Min-Max Scaling on the Iris dataset.\n",
    "\n",
    "\n",
    "\n",
    "# Question 3: Standardization (Z-score Scaling)\n",
    "# Task: Implement Standardization using Z-score scaling on the Iris dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Question 4: Robust Scaling\n",
    "# Task: Implement Robust Scaling to handle outliers in the Iris dataset.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy without scaling: 1.0\n",
      "Accuracy with Min-Max Scaling: 1.0\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0           0.222222          0.625000           0.067797          0.041667\n",
      "1           0.166667          0.416667           0.067797          0.041667\n",
      "2           0.111111          0.500000           0.050847          0.041667\n",
      "3           0.083333          0.458333           0.084746          0.041667\n",
      "4           0.194444          0.666667           0.067797          0.041667\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0          -0.900681          1.019004          -1.340227         -1.315444\n",
      "1          -1.143017         -0.131979          -1.340227         -1.315444\n",
      "2          -1.385353          0.328414          -1.397064         -1.315444\n",
      "3          -1.506521          0.098217          -1.283389         -1.315444\n",
      "4          -1.021849          1.249201          -1.340227         -1.315444\n",
      "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)\n",
      "0          -0.538462               1.0          -0.842857         -0.733333\n",
      "1          -0.692308               0.0          -0.842857         -0.733333\n",
      "2          -0.846154               0.4          -0.871429         -0.733333\n",
      "3          -0.923077               0.2          -0.814286         -0.733333\n",
      "4          -0.615385               1.2          -0.842857         -0.733333\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
    "\n",
    "# Model without scaling\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train, y_train)\n",
    "y_pred = knn.predict(X_test)\n",
    "print(\"Accuracy without scaling:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Model with Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "knn.fit(X_train_scaled, y_train)\n",
    "y_pred_scaled = knn.predict(X_test_scaled)\n",
    "print(\"Accuracy with Min-Max Scaling:\", accuracy_score(y_test, y_pred_scaled))\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert to DataFrame for better readability\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=feature_names)\n",
    "print(df_scaled.head())\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Apply StandardScaler (mean=0, std=1)\n",
    "scaler = StandardScaler()\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "df_standardized = pd.DataFrame(X_standardized, columns=feature_names)\n",
    "print(df_standardized.head())\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# Apply RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_robust_scaled = scaler.fit_transform(X)\n",
    "\n",
    "df_robust = pd.DataFrame(X_robust_scaled, columns=feature_names)\n",
    "print(df_robust.head())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
